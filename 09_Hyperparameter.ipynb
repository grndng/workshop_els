{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea1d23e1",
   "metadata": {},
   "source": [
    "#  Hyperparameter verstehen\n",
    "\n",
    "In diesem Notebook geht es um **Hyperparameter** in Machine Learning und Deep Learning.\n",
    "\n",
    "Ziele:\n",
    "- verstehen, was ein *Hyperparameter* ist,\n",
    "- typische Hyperparameter in neuronalen Netzen kennenlernen,\n",
    "- besonders: die **Learning Rate** als Beispiel für ein Optimierungsproblem,\n",
    "- den Bezug zu unserer **Gebäudesegmentierung mit dem U-Net** herstellen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6288bb74",
   "metadata": {},
   "source": [
    "## 1. Was sind Hyperparameter?\n",
    "\n",
    "In einem neuronalen Netz gibt es zwei Arten von Größen:\n",
    "\n",
    "**1. Parameter (Gewichte des Modells)**\n",
    "- werden **vom Training gelernt** (z. B. Filtergewichte in Convolution-Layern).\n",
    "- Beispiel U-Net: die Gewichte in den `Conv2d`-Schichten, die lernen, wie Gebäude aussehen.\n",
    "\n",
    "**2. Hyperparameter**\n",
    "- werden **nicht** direkt gelernt,\n",
    "- sondern **von uns eingestellt**, bevor das Training startet.\n",
    "\n",
    "Typische Hyperparameter:\n",
    "- Learning Rate (Lernrate)\n",
    "- Anzahl Epochen (Wie oft sollen alle Bilder durch das Modell geschleust werden während des Trainings?)\n",
    "- Batch Size (Wie viele Bilder werden gleichzeitig durch das Netz \"geschleust\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceceed29",
   "metadata": {},
   "source": [
    "## 2. Learning Rate – ein Optimierungsproblem\n",
    "\n",
    "Die **Learning Rate** bestimmt, wie große Schritte das Modell beim Lernen macht.\n",
    "\n",
    "Wir können uns das wie das Herunterlaufen eines Hügels vorstellen:\n",
    "\n",
    "- Du stehst irgendwo auf einem Hügel.\n",
    "- Du möchtest ins **Tal** (Minimum der Fehlerfunktion).\n",
    "- In jeder Runde schaust du, in welche Richtung es **bergab** geht (Gradient).\n",
    "- Mit der Learning Rate entscheidest du, **wie große Schritte** du machst.\n",
    "\n",
    "Was kann passieren?\n",
    "- Ist die Learning Rate **zu klein**, brauchst du sehr lange, um anzukommen.\n",
    "- Ist sie **zu groß**, springst du vielleicht am Tal vorbei oder sogar hin und her.\n",
    "- Es gibt einen guten Bereich → das Training wird schnell und stabil.\n",
    "\n",
    "Genau das passiert auch beim Training unseres U-Nets für Gebäudesegmentierung: Die Learning Rate bestimmt, wie stark sich die Gewichte nach jedem Batch verändern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48847c16",
   "metadata": {},
   "source": [
    "### 2.1 Ein einfaches 2D-Optimierungsproblem\n",
    "\n",
    "Wir betrachten eine einfache Funktion in 2D, die wie eine **Schüssel** aussieht: Das Minimum dieser Funktion liegt bei 0 - im Zentrum der Schüssel. Wir starten an einem zufälligen Punkt und benutzen **Gradientenabstieg**, um ins Tal zu kommen. Die Learning Rate steuert die Schrittgröße."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6bc2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "def f(w1, w2):\n",
    "    return w1**2 + 0.5 * w2**2\n",
    "\n",
    "def grad_f(w1, w2):\n",
    "    df_dw1 = 2 * w1\n",
    "    df_dw2 = 1.0 * w2\n",
    "    return np.array([df_dw1, df_dw2])\n",
    "\n",
    "def gradient_descent(start, lr=0.1, n_steps=20):\n",
    "    w = np.array(start, dtype=float)\n",
    "    trajectory = [w.copy()]\n",
    "    for i in range(n_steps):\n",
    "        g = grad_f(w[0], w[1])\n",
    "        w = w - lr * g\n",
    "        trajectory.append(w.copy())\n",
    "    return np.array(trajectory)\n",
    "\n",
    "start_point = (2.5, 2.0)\n",
    "traj_small = gradient_descent(start_point, lr=0.02, n_steps=40)\n",
    "traj_good  = gradient_descent(start_point, lr=0.1,  n_steps=20)\n",
    "traj_big   = gradient_descent(start_point, lr=0.4,  n_steps=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1436dae9",
   "metadata": {},
   "source": [
    "### 2.2 Vergleich: kleine, gute und große Learning Rate (statisch)\n",
    "\n",
    "Wir zeichnen die Funktion als Konturplot und darüber die Wege, die Gradient Descent für verschiedene Learning Rates geht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237302ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_point = (2.5, 2.0)\n",
    "\n",
    "# bewusst gewählte Lernraten\n",
    "lr_small = 0.02     # zu klein\n",
    "lr_good  = 0.15      # gut\n",
    "lr_big   = 0.95      # zu groß (über Stabilitätsgrenze)\n",
    "\n",
    "traj_small = gradient_descent(start_point, lr=lr_small, n_steps=40)\n",
    "traj_good  = gradient_descent(start_point, lr=lr_good,  n_steps=20)\n",
    "traj_big   = gradient_descent(start_point, lr=lr_big,   n_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f23818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "cs = plt.contour(W1, W2, Z, levels=20)\n",
    "plt.clabel(cs, inline=True, fontsize=8)\n",
    "\n",
    "plt.plot(traj_small[:,0], traj_small[:,1], 'o-', label=f'LR = {lr_small} (zu klein)')\n",
    "plt.plot(traj_good[:,0],  traj_good[:,1],  'o-', label=f'LR = {lr_good} (gut)')\n",
    "plt.plot(traj_big[:,0],   traj_big[:,1],   'o-', label=f'LR = {lr_big} (zu groß)')\n",
    "\n",
    "plt.scatter([0],[0], color='red', marker='x', s=100, label='Minimum')\n",
    "plt.xlabel('w1')\n",
    "plt.ylabel('w2')\n",
    "plt.title('Gradientenabstieg für verschiedene Learning Rates')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf0daf2",
   "metadata": {},
   "source": [
    "### 2.3 2D-Animation für eine Learning Rate\n",
    "\n",
    "Jetzt animieren wir den Weg eines Punktes für bestimmte Learning Rates (z. B. `lr = 0.02`, `lr = 0.15`, `lr = 0.95`). Das entspricht der **Optimierung der Gewichte** in unserem U-Net – nur dass wir hier statt Millionen Gewichten\n",
    "nur zwei Parameter haben und sie sehen können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992c3ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs    = [lr_small, lr_good, lr_big]\n",
    "labels = [\n",
    "    f\"LR = {lr_small} (zu klein)\",\n",
    "    f\"LR = {lr_good} (gut)\",\n",
    "    f\"LR = {lr_big} (zu groß)\"\n",
    "]\n",
    "trajs  = [traj_small, traj_good, traj_big]\n",
    "colors = [\"blue\", \"red\", \"green\"]\n",
    "\n",
    "max_steps = max(len(t) for t in trajs)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "cs = ax.contour(W1, W2, Z, levels=20)\n",
    "ax.clabel(cs, inline=True, fontsize=8)\n",
    "\n",
    "points = []\n",
    "paths = []\n",
    "for c, lab in zip(colors, labels):\n",
    "    p, = ax.plot([], [], \"o\", color=c, label=lab)\n",
    "    line, = ax.plot([], [], \"--\", color=c, alpha=0.7)\n",
    "    points.append(p)\n",
    "    paths.append(line)\n",
    "\n",
    "ax.scatter([0], [0], color=\"black\", marker=\"x\", s=80, label=\"Minimum\")\n",
    "ax.set_xlim(-3, 3)\n",
    "ax.set_ylim(-3, 3)\n",
    "ax.set_xlabel(\"w1\")\n",
    "ax.set_ylabel(\"w2\")\n",
    "ax.set_title(\"Gradientenabstieg für verschiedene Learning Rates\")\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.grid(True)\n",
    "\n",
    "def init():\n",
    "    for p, line in zip(points, paths):\n",
    "        p.set_data([], [])\n",
    "        line.set_data([], [])\n",
    "    return points + paths\n",
    "\n",
    "def update(frame):\n",
    "    for traj, p, line in zip(trajs, points, paths):\n",
    "        idx = min(frame, len(traj) - 1)\n",
    "        w = traj[idx]\n",
    "        p.set_data([w[0]], [w[1]])                      # Punkt als Sequenz\n",
    "        line.set_data(traj[:idx+1, 0], traj[:idx+1, 1]) # Pfad\n",
    "    ax.set_title(f\"Gradientenabstieg – Schritt {frame}\")\n",
    "    return points + paths\n",
    "\n",
    "anim = animation.FuncAnimation(\n",
    "    fig,\n",
    "    update,\n",
    "    init_func=init,\n",
    "    frames=max_steps,\n",
    "    interval=500,\n",
    "    blit=True\n",
    ")\n",
    "\n",
    "plt.close(fig)\n",
    "HTML(anim.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4a755e",
   "metadata": {},
   "source": [
    "## 3. Bezug zur Gebäudesegmentierung\n",
    "\n",
    "In unserem U-Net für Gebäudesegmentierung gibt es **sehr viele Parameter** (Gewichte in allen Convolution-Layern).\n",
    "Die Optimierung dieser Gewichte passiert mit genau derselben Idee wie im 2D-Beispiel:\n",
    "\n",
    "- Wir berechnen einen **Fehler** (Loss) zwischen Vorhersage-Maske (Prediction) und Ground Truth.\n",
    "- Wir berechnen den **Gradienten** dieses Fehlers bezüglich aller Gewichte.\n",
    "- Wir machen einen Schritt in Richtung \"bergab\".\n",
    "- Die **Learning Rate** bestimmt die Schrittgröße.\n",
    "\n",
    "Bei zu großer Learning Rate könnte das U-Net instabil lernen, bei zu kleiner Learning Rate lernt es nur sehr langsam.\n",
    "In der Praxis testet man oft mehrere Learning Rates und wählt einen Bereich, in dem das Training stabil und schnell ist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baadfb19",
   "metadata": {},
   "source": [
    "## 4. Weitere wichtige Hyperparameter\n",
    "\n",
    "### 4.1 Anzahl Epochen\n",
    "- Eine **Epoche** bedeutet: das Netz hat alle Trainingsbeispiele einmal gesehen.\n",
    "- Wenige Epochen → das Netz hat zu wenig gelernt (Underfitting).\n",
    "- Zu viele Epochen → Gefahr von **Overfitting**.\n",
    "\n",
    "### 4.2 Batch-Größe\n",
    "- Statt **ein Bild nach dem anderen** zu verarbeiten, nehmen wir Batches (z. B. 8 Bilder).\n",
    "- Kleine Batches:\n",
    "  - mehr Rauschen im Gradienten,\n",
    "  - oft besser für Generalisierung, aber langsamer.\n",
    "- Große Batches:\n",
    "  - glattere Gradienten,\n",
    "  - effizienter auf GPUs, aber brauchen mehr Speicher.\n",
    "\n",
    "### 4.3 Modelltiefe und Anzahl der Filter\n",
    "- Mehr Encoder-/Decoder-Stufen → das U-Net sieht mehr **Kontext**.\n",
    "- Mehr Filter → das Netz kann mehr Muster lernen.\n",
    "- Aber: mehr Parameter = mehr Rechenzeit + mehr Overfitting-Risiko.\n",
    "In unserem Mini-U-Net haben wir bewusst ein **kleines Modell** gewählt, damit es im Workshop schnell trainierbar bleibt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705b2e34",
   "metadata": {},
   "source": [
    "## 5. Mini-Übungsaufgaben\n",
    "\n",
    "1. **Startpunkt variieren:**\n",
    "   - Ändert `start_point = (2.5, 2.0)` zu z. B. `(-2, 2)` oder `(1, -3)`.\n",
    "   - Was passiert mit der Trajektorie?\n",
    "\n",
    "2. **Verbindung zum U-Net:**\n",
    "   - Öffnet das U-Net-Notebook.\n",
    "   - Sucht die Stelle mit `optimizer = torch.optim.Adam(..., lr=1e-3)`.\n",
    "   - Überlegt: Was würde passieren, wenn ihr `1e-2` oder `1e-4` nehmt?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
